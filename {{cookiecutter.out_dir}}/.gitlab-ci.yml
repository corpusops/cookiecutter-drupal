image: {name: "${COMPOSE_IMAGE}", entrypoint: [""]}
{%- set gitlabci_envs = [] %}{% for i in ['dev', 'qa', 'staging', 'prod', 'preprod']%}{% if cookiecutter[i+'_host'] %}{% set _ = gitlabci_envs.append(i)%}{%endif%}{%endfor%}
{%- set gitlabci_branches = [] %}{% for i in gitlabci_envs %}{% set _ = gitlabci_branches.append(cookiecutter.get(i+'_branch', i)) %}{%endfor %}
{%- set devhostdeploycomment = (not cookiecutter.dev_host) and '#  ' or '' %}
{%- set qahostdeploycomment = (not cookiecutter.qa_host) and '#  ' or '' %}
{%- set staginghostdeploycomment = (not cookiecutter.staging_host) and '#  ' or '' %}
{%- set preprodhostdeploycomment = (not cookiecutter.preprod_host) and '#  ' or '' %}
{%- set prodhostdeploycomment = (not cookiecutter.prod_host) and '#  ' or '' %}
{%- set envs = ['dev', 'qa', 'staging', 'prod', 'preprod'] %}
{%- set aenvs = [] %}{%- for i in envs %}{% if cookiecutter.get(i+'_host', '')%}{% set _ = aenvs.append(i) %}{%endif%}{%endfor%}
{%- set devhostdeploycomment = (not cookiecutter.dev_host) and '#  ' or '' %}
{%- set frontcomment = (not cookiecutter.with_bundled_front) and '#  ' or '' %}
{%- set teleportcomment = (not cookiecutter.with_teleport_stagingprod_jobs) and '#  ' or '' %}
{%- set staticscomment = (not (cookiecutter.with_bundled_front or cookiecutter.with_bundled_docs)) and '#  ' or '' %}
{%- set docscomment = (not cookiecutter.with_bundled_docs) and '#  ' or '' %}
{%- set testsc = (not cookiecutter.test_tests) and '#' or '' -%}
{%- set lintingc = (not cookiecutter.test_linting) and '#' or '' %}
# - To setup the pipeline you need to configure those CICD Variables:
# - CORPUSOPS_VAULT_PASSWORD if deploying with ansible
# - CA_CERTIFICATES_PATHS (opt): custom path to CACERT(s) (space separated) for gitlab, docker & registry available both for runner and spawned containers
# - DOCKER_AUTH_CONFIG: see below
# - make sure:
#    - pull_policy is `always`
#    - cachedir (/cache) and builddir (/builds) runner directories are shared between stages
#    - umask is set in a pre_clone_script (pre_clone_script = "umask 0022").
#    - DOCKER_AUTH_CONFIG is configured and contains all required auths in each context (your private registry, dockerhub) both inside runner config (for dockerhub only) and inside your CICD variables (both dockerhub & private registry)
# The CICD var should like
#   DOCKER_AUTH_CONFIG: {"auths":{"https://index.docker.io/v1/": {"auth": "xxx=="},"{{cookiecutter.docker_registry}}":{"auth":"xxx=="}}}
# The Runner config should like
#  [[runners]]
#  environment=["DOCKER_AUTH_CONFIG={\"auths\":{\"https://index.docker.io/v1/\":{\"auth\":\"xxx=\"}}}","DOCKER_TLS_CERTDIR="]
#  builds_dir="/srv/nobackup/gitlabrunner/builds"
#  cache_dir="/cache"
#  pre_clone_script="umask 0022"

# /!\  /!\  /!\
# - We use (ba)sh -c to enforce multiple levels of variables resolution,
#   please see https://gitlab.com/gitlab-org/gitlab-runner/-/issues/1809
#   Indeed, gitlab-ci would not interpret multiple nested variables (variable-in-variable)
#   Even if gitlab is doing better nowodays, we need to keep them as this was close very lately
#   and we still need to deploy on pretty old gitlabs where bug remains.
# - We do not use buildx(buildkit) remote image caching because of bugs in target registries (https://github.com/moby/buildkit/issues/2251)
# /!\  /!\  /!\

stages:
- manual_jobs
- build_ci
- build_artifacts
- test
- end_flag
- release
- post_release
- post_deploy

variables: &variables
  # Keep this two next vars
  GIT_SSL_CAPATH: /etc/ssl/certs/
  GIT_SUBMODULE_STRATEGY: recursive
  # we need for now a specific dind version to be sure to use Buildkit to build images (cache & speed gain)
  # but then legacy builder to squash them (as a side effect to drastically shrink down their size)
  # DOCKERDIND_IMAGE: "docker:20.10.0-beta1-dind"
  DOCKER_IMAGE: "{{cookiecutter.simple_docker_image}}"
{%- if not cookiecutter.remove_varnish %}
  DOCKER_IMAGE_VARNISH: "{{cookiecutter.simple_docker_image_varnish}}"
{%- endif %}
  DOCKERDIND_IMAGE: "{{cookiecutter.dind_image}}"
  DOCKER_TEST_IMAGE: "{{cookiecutter.docker_test_image}}"
  CORPUSOPS_IMAGE: "{{cookiecutter.corpusops_image}}"
  COMPOSE_IMAGE: "{{cookiecutter.compose_image}}"
  REGISTRY_IMAGE: "{{cookiecutter.registry_image}}"
  NODE_IMAGE: "{{cookiecutter.node_image}}"
  #
  # Configure your registry credentials in your CI secret variables
  DOCKER_REGISTRY: "{{cookiecutter.docker_registry}}"
  # services launched during tests
  DOCKER_SERVICES: "db{% if cookiecutter.cache_system%} {{cookiecutter.cache_system}}{%endif%} mailcatcher"
  # cache registry setup
  REGISTRIES_CACHE_DIR: /cache/cachedockerregistrysimple
  # Build pipeline images flavors: build/tags/{{cookiecutter.main_branch}}
  # Released images flavors: build/forcedrelease/tags/{{cookiecutter.main_branch}}
  LATEST_CI_DOCKER_IMAGE: "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:ci-latest"
  REF_CI_DOCKER_IMAGE: "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:ci-${CI_COMMIT_REF_NAME}"
  CUR_CI_DOCKER_IMAGE: "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:ci-${CI_PIPELINE_IID}"
  LATEST_DOCKER_IMAGE: "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:latest"
  REF_DOCKER_IMAGE: "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${CI_COMMIT_REF_NAME}"
  CUR_DOCKER_IMAGE: "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${CI_PIPELINE_IID}"
{%- if not cookiecutter.remove_varnish %}
  # varnish tags
  LATEST_CI_DOCKER_IMAGE_VARNISH: "${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:ci-latest"
  REF_CI_DOCKER_IMAGE_VARNISH: "${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:ci-${CI_COMMIT_REF_NAME}"
  CUR_CI_DOCKER_IMAGE_VARNISH: "${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:ci-${CI_PIPELINE_IID}"
  LATEST_DOCKER_IMAGE_VARNISH: "${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:latest"
  REF_DOCKER_IMAGE_VARNISH: "${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:${CI_COMMIT_REF_NAME}"
  CUR_DOCKER_IMAGE_VARNISH: "${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:${CI_PIPELINE_IID}"
{%- endif %}
  # default to $TAGGUABLE_IMAGE_BRANCH
  IMAGE_FLAVORS: "((-?(latest|dev))|((docs|js)builder))?(-dev)?"
  EXTRA_DOCKER_TAGS: "^((docs|js)builder)$"
  # branches than can produce docker image tags
  MAIN_BRANCH: {{cookiecutter.main_branch}}
  TAGGUABLE_IMAGE_BRANCH: "^(latest|{{cookiecutter.main_branch}}|dev|qa|staging|preprod|prod)$"
  # Allow to have many compose stacks aside.
  COMPOSE_PROD_CONFIGS: docker-compose.yml:docker-compose-prod.yml:docker-compose-build.yml
  COMPOSE_DEV_CONFIGS:  docker-compose.yml:docker-compose-dev.yml:docker-compose-build.yml:docker-compose-build-dev.yml
  DOCKER_VOLUMES: "publiccontrib:$CI_PROJECT_DIR/app/var/public private:$CI_PROJECT_DIR/app/var/private webroot:$CI_PROJECT_DIR/app/var/nginxwebroot data:$CI_PROJECT_DIR/data docs:$CI_PROJECT_DIR/outdocs"
  DEPLOY_PLAYBOOK: "{{cookiecutter.deploy_playbook}}"
  DOCKER_BUILDER:     corpusops
  DOCKER_CACHE:         /cache/$CI_PROJECT_PATH_SLUG/dockercache
  WORKSPACE:            /cache/$CI_PROJECT_PATH_SLUG/w/${CI_PIPELINE_IID}
  # $COMMON_HOSTS_FILE is a workaround for https://gitlab.com/gitlab-org/gitlab-runner/-/issues/1042
  # we wait for main container to start to share its /etc/hosts and ensure name resolution between services
  COMMON_HOSTS_FILE:  /cache/$CI_PROJECT_PATH_SLUG/w/${CI_PIPELINE_IID}/${CI_JOB_STAGE}___${CI_JOB_NAME}.hosts
  #
  NONINTERACTIVE: "1"
  TZ: Europe/Paris
  # debug
  NO_SILENT: ""
  NO_SQUASH: ""
  SDEBUG: "$NO_SILENT"
  SHELL_DEBUG: "${NO_SILENT}"
  CA_CERTIFICATES_PATHS: "${CA_CERTIFICATES_PATHS}"
{%-if cookiecutter.use_submodule_for_deploy_code%}
  # auto upgrade common glue code to reference stable branch (see pullsubmodules)
  PROJECT_COMMON_DEPLOY_DIR: {{cookiecutter.deploy_project_dir}}
  {{cookiecutter.app_type.upper()}}_DEPLOY_VERSION: origin/v2
{%- endif %}
  # set to 1 to force reinstall
  {{cookiecutter.app_type.upper()}}_FORCE_INSTALL: ""

# Forward correctly UI defined env vars to compagnion services as documented on:
# https://gitlab.com/gitlab-org/gitlab-foss/-/merge_requests/30863
.service_vars:
  variables: &service_vars
    CA_CERTIFICATES_PATH: "${CA_CERTIFICATES_PATH}"
    CA_CERTIFICATES_PATHS: "${CA_CERTIFICATES_PATHS}"
    CORPUSOPS_VAULT_PASSWORD: "${CORPUSOPS_VAULT_PASSWORD}"

.ci_runner: &ci_runner
  tags: ["{{cookiecutter.runner_tag}}"]

.build_rules: &build_rules
  rules:
  - &skip_mr_trigger {if: "$CI_PIPELINE_SOURCE =~ /merge_request/", when: never}
  - &skip_not_on_ui_trigger {if: "$CI_PIPELINE_SOURCE !~ /^(api|parent_pipeline|pipeline|push|trigger)/", when: never}
  - &on_manual_trigger {when: manual}
  - &skip_not_a_push_trigger {if: "$CI_PIPELINE_SOURCE !~ /push/", when: never}
  - &skip_not_main_trigger                      {if: "$CI_COMMIT_REF_NAME != $MAIN_BRANCH", when: never}
  - &skip_on_release_branches_main_tags_trigger {if: "$CI_COMMIT_REF_NAME =~ /^({{gitlabci_branches|join('|')}})$/ || $CI_COMMIT_REF_NAME != $MAIN_BRANCH || $CI_COMMIT_TAG == null", when: never}
  - &skip_on_release_branches_tags_trigger      {if: "$CI_COMMIT_REF_NAME =~ /^({{gitlabci_branches|join('|')}})$/{% if not cookiecutter.no_tags_pipelines%} || $CI_COMMIT_TAG != null{%endif%}", when: never}
  - &on_release_branches_main_tags_trigger      {if: "$CI_COMMIT_REF_NAME =~ /^({{gitlabci_branches|join('|')}})$/ || $CI_COMMIT_REF_NAME == $MAIN_BRANCH{% if not cookiecutter.no_tags_pipelines%} || $CI_COMMIT_TAG != null{%endif%}", when: on_success}
  - &mon_release_branches_main_tags_trigger     {if: "$CI_COMMIT_REF_NAME =~ /^({{gitlabci_branches|join('|')}})$/ || $CI_COMMIT_REF_NAME == $MAIN_BRANCH{% if not cookiecutter.no_tags_pipelines%} || $CI_COMMIT_TAG != null{%endif%}", when: manual}
  - &on_release_branches_tags_trigger           {if: "$CI_COMMIT_REF_NAME =~ /^({{gitlabci_branches|join('|')}})$/{% if not cookiecutter.no_tags_pipelines%} || $CI_COMMIT_TAG != null{%endif%}", when: on_success}
  - &on_main_and_tags_trigger                   {if: "$CI_COMMIT_REF_NAME == $MAIN_BRANCH || $CI_COMMIT_TAG == null", when: on_success}
.manual_releasable: &manual_releasable {rules: [ *skip_mr_trigger, *mon_release_branches_main_tags_trigger, {when: never} ]}

.manual_job: &manual_job
  <<: [ *ci_runner ]
  allow_failure: true
  stage: manual_jobs
  when: manual

before_script: &top_before_script
- &definefuncs |-
   set -eo pipefail;
   if [ ! -e "${WORKSPACE}" ];then mkdir -pv ${WORKSPACE};fi;
   if [ ! -e "${WORKSPACE}/funcs" ];then cat>"${WORKSPACE}/funcs"<<'EOF'
   bx_bake_tags() { tags="$@";if [ "x$tags" != "x" ];then echo "--push --set *.tags= ";for i in $tags;do echo "--set *.tags=$i";done;fi; }
   bx_dc() { dc_ --print "$@" && dc_ "$@"; }
   dcompose_bx_() { docker buildx bake --builder ${DOCKER_BUILDER} -f ${COMPOSE_FILE//:/ -f } --set "*.args.BUILDKIT_INLINE_CACHE=" $@; }
   uniquify() { echo $@|xargs -n1|awk '!seen[$0]++'; }
   dockerregistertag() { vv docker tag ${1} ${2};tags="$(uniquify ${tags} ${2})"; }
   create_dirs() { for i in $@;do if [ ! -e "$i" ];then mkdir -pv "${i}";fi;done; }
   add_cacrt() {
    if [ "x${@-${CA_CERTIFICATES_PATHS-}${CA_CERTIFICATES_PATH-}}" = "x" ];then return 0;fi
    if (apk --version >/dev/null 2>&1);then apk add ca-certificates;fi
    if (apt-get --version >/dev/null 2>&1);then apt-get install -y ca-certificates;fi
    todo="" && for capath in ${@-${CA_CERTIFICATES_PATHS-} ${CA_CERTIFICATES_PATH-}};do
      if [ -e "${capath}" ];then log "Add custom CACERT: $capath" && cp -f "${capath}" /usr/local/share/ca-certificates && todo=1;fi
    done && if [ "x$todo" != "x" ];then
      aln="" && if [ -e /etc/ssl/cert.pem ];then aln=1;rm /etc/ssl/cert.pem;fi # fix alpine bug
      update-ca-certificates --fresh
      if [ "x$aln" != "x" ];then ln -s /etc/ssl/certs/ca-certificates.crt /etc/ssl/cert.pem;fi
    fi
   }
   adddockertag() {
    dockerregistertag ${1}     $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${2})
    dockerregistertag ${1}-dev $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${2}-dev)
{%- if not cookiecutter.remove_varnish %}
    dockerregistertag ${3}     $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:${2})
    dockerregistertag ${3}-dev $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:${2}-dev)
{%- endif %}
   }
   bx_adddockertag() {
    if [ "$1" != "$(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${2})" ];then
      retry_cmd vv docker buildx imagetools create ${1}     -t $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${2})
      retry_cmd vv docker buildx imagetools create ${1}-dev -t $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${2})-dev
{%- if not cookiecutter.remove_varnish %}
      retry_cmd vv docker buildx imagetools create ${3}     -t $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:${2})
      retry_cmd vv docker buildx imagetools create ${3}-dev -t $(eval echo ${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:${2})-dev
{%- endif %}
    else
      log "docker tag $1 is already done"
    fi
   }
   log() { echo "$@">&2; }
   die() { log "$@";exit 1; }
   vv() { log "$@";"$@"; }
   retry_cmd() { retries=${retries:-10};sleep=${sleep:-1};i=0;until ( "$@" );do i=$(($i+1));test $i -gt ${retries} && return 1;sleep ${sleep};done;return 0; }
   wait_ready() { s="${s:-0.5}";t="${t:-800}";start=$(date +%s);until ("$@";);do
    d=$(date +%s);dt=$((${d}-${start}));if [ ${dt} -gt ${t} ];then echo "  no more retries: $@" >&2;return 1;fi
    if [ $(( ${dt} % ${CI_OPEN_MSG_DELAY:-240} )) -eq 0 ];then echo "  CI keeps open" >&2;fi
    (cat /dev/zero|read -t ${s}||exit 0);done; }
   vwait_ready() { vv wait_ready "$@"; }
   wait_docker() { docker system info >/dev/null 2>&1; }
   # see https://gitlab.com/gitlab-org/gitlab-runner/-/issues/28121: workaround to have shared-alike-volumes between services & local script inside $CI_PROJECT_DIR
   setup_docker_volumes() {
     set -e;w="${CI_PROJECT_DIR}/gitlab_docker_volumes";for i in $(eval echo ${DOCKER_VOLUMES});do
       d="${i//*:}";o="$w/$CI_JOB_NAME/${i//:*}";create_dirs "$o" "$d";
       if [ -e "$d" ];then
        # transfer any existing file to the shared directory
        while read sd;do if [ -e "$d/$sd" ];then cp -rf "$d/$sd" "$o"/;fi;done < <(cd "$d" && find -mindepth 1 -maxdepth 1 \( -type f -or -type d \) )
        rm -rf "$d"
       fi
       ln -sfv "$o" "$d"
     done
   } 
   # see https://github.com/moby/buildkit/issues/1896: swap cache folder upon new image creation to avoid eternaly growing cache
   swap_cache_folder() {
     for i in $@;do log "swap docker cache_folder: $i"
       if [ -e "${i}.new" ];then if [ -e "${i}" ];then rm -rf "${i}";fi && mv -f "${i}.new" "${i}";fi
       if [ -e "{i}" ] && [ ! -e "${i}/index.json" ];then log "Deleting corrupted buildkit folder: $i";rm -rf "${i}";fi
     done
   }
   EOF
   fi;. "${WORKSPACE}/funcs"
- &setup_docker_volumes setup_docker_volumes
- &pullsubmodules
    git config --global safe.directory '*';
    if !( echo ${GIT_SUBMODULE_STRATEGY-} | grep -E -q none );then set -e;
    if ! ( git --version >/dev/null 2>&1 );then
     if ( apk --version );then apk update;apk add git;
     elif ( apt-get --version );then apt-get update;apt-get install -y git;fi;
    fi;
    cd ${PROJECT_COMMON_DEPLOY_DIR};( git fetch --unshallow >/dev/null 2>&1 || true );git config remote.origin.fetch "+refs/heads/*:refs/remotes/origin/*";git fetch origin;git reset --hard ${{cookiecutter.app_type.upper()}}_DEPLOY_VERSION --;cd - >/dev/null 2>&1;
    fi
- &install_bash if !( bash --version >/dev/null 2>&1 ) && [ "x${INSTALL_BASH-1}" = "x1" ];then if (apk --version >/dev/null 2>&1 );then apk update && apk add -q bash;elif ( apt-get --version >/dev/null 2>&1 );then apt-get update -qq && apt-get install -yqq bash;fi;fi
- &settz ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo ${TZ} > /etc/timezone
- &gendotenv |-
    set -e;if ! ( envsubst --version >/dev/null 2>&1 );then apk update;apk add gettext;fi;
    for i in SHELL_DEBUG SDEBUG NO_STARTUP_LOGS NO_SILENT;do eval printf "$i=\${$i-}\\\n">>.env.dist;done
    for env in .env docker.env;do cat ${env}.dist | envsubst | sed -r \
    -e "s/^(CI_COMMIT_SHA=).*/\\1${CI_COMMIT_SHA}/g" > $env;done

# to speed up pipelines, we add a proxy registry to cache downloads in local cache
# Accelerate dind builds:
#   - by caching downloaded docker images in a local service available at registriescache:5000
.dind: &dind
  variables: &dind_variables
    <<: [ *service_vars, *variables ]
    CREDS_HELPER_URL: "https://raw.githubusercontent.com/corpusops/docker-gitlabtools/main/rootfs/common/bin/docker-credential-copsgitlab"
    CREDS_HELPER_INIT: "1"
    DOCKER_BUILDKIT: "1"
    COMPOSE_DOCKER_CLI_BUILD: "1"
    BUILDKIT_PROGRESS: plain
    DOCKER_HOST: tcp://docker:2375
    DOCKER_DRIVER: overlay2
    BUILDKIT_IMAGE: "moby/buildkit:buildx-stable-1"
  services: &docker_client_services
  #- {name: busybox, entrypoint: [sh, '-c', 'export && sleep 5000 && exit 1']}
  # registry caches both for dockerhub(port:5000) & private registry(port:5001)
  - &docker_registries
    name: "${REGISTRY_IMAGE}"
    alias: registriescache
  - &docker_client
    name: "${DOCKERDIND_IMAGE}"
    alias: docker
    variables:
      HTTP_PROXY: "http://registriescache:3128"
      HTTPS_PROXY: "http://registriescache:3128"
  after_script: &dind_after_script
  - &remove_commonhosts_file set -e && if [ -e "${COMMON_HOSTS_FILE}" ];then rm -vf "${COMMON_HOSTS_FILE}";fi
  before_script: &dind_before_script
  - *definefuncs
  - *pullsubmodules
  - &waitforservices |-
    set -e
    add_cacrt
    t=${DOCKER_SERVICES_TIMEOUT:-60} wait_ready grep -E "^[^#].*\s(docker|registriescache)" /etc/hosts >/dev/null
    grep -E "^[^#].*\s(docker|registriescache)" /etc/hosts > "${COMMON_HOSTS_FILE}"
    t=${DOCKER_TIMEOUT:-100} vwait_ready wait_docker
    t=${DOCKER_PULLTEST_TIMEOUT:-$(($DOCKER_TIMEOUT+160))} vwait_ready docker pull ${DOCKER_TEST_IMAGE}
  - *gendotenv
  - &setupdotenv |-
    sed -i -re "/[^=]_IMAGE(_VERSION)=/ d" .env
    cat >>.env<<EOF
    {{cookiecutter.app_type.upper()}}_IMAGE=$(echo ${BUILT_DOCKER_IMAGE}|sed -re "s/((.*:?.*)(:[^:]+))/\2/g")
    {{cookiecutter.app_type.upper()}}_IMAGE_VERSION=$(echo ${BUILT_DOCKER_IMAGE}|sed -re "s/.*://g")
{%- if not cookiecutter.remove_varnish %}
    VARNISH_IMAGE=$(echo ${BUILT_DOCKER_IMAGE_VARNISH}|sed -re "s/((.*:?.*)(:[^:]+))/\2/g")
    VARNISH_IMAGE_VERSION=$(echo ${BUILT_DOCKER_IMAGE_VARNISH}|sed -re "s/.*://g")
{%- endif %}
    EOF
  - &docker_auth |-
    set -e
    # authenticate builds & dockerhub
    if [ "x{DOCKER_AUTH_CONFIG-}" != "x" ];then log "Configuring docker auth";if [ ! -d ~/.docker ];then mkdir -pv ~/.docker;fi;echo "$DOCKER_AUTH_CONFIG">~/.docker/config.json;fi
  - &setup_docker |-
    set -e
    # allow custom cacert in builkdit build container
    ow=$(pwd) && d=$(mktemp -d) && todo=""
    printf "FROM ${BUILDKIT_IMAGE}\n">"$d/Dockerfile"
    for capath in ${CA_CERTIFICATES_PATHS-} ${CA_CERTIFICATES_PATH-};do if [ -e "${capath}" ];then todo=1;cp ${capath} $d;fi;done
    if [ "x$todo" != "x" ];then
      BUILDKIT_IMAGE="custombuildkit-builder"
      printf "ADD *.crt /usr/local/share/ca-certificates/\n">>"$d/Dockerfile"
      printf "RUN if [ -e /etc/ssl/cert.pem ];then rm /etc/ssl/cert.pem;fi;update-ca-certificates --fresh\n">>"$d/Dockerfile"
      docker build -t ${BUILDKIT_IMAGE} "$d" -f "$d/Dockerfile"
    fi
    # setup buildkitd
    if [ ! -e "$DOCKER_CACHE" ];then mkdir -pv "$DOCKER_CACHE";fi
    if !(docker buildx inspect ${DOCKER_BUILDER} >/dev/null 2>&1);then
      docker buildx create --name ${DOCKER_BUILDER} --driver docker-container --driver-opt image=${BUILDKIT_IMAGE} --buildkitd-flags '--debug'
    fi
    docker buildx use ${DOCKER_BUILDER} --global >/dev/null

cleanup_project: &cleanup_project
  <<: [ *manual_job ]
  rules: [ *skip_mr_trigger, *skip_not_main_trigger, *on_manual_trigger ]
  dependencies: []
  before_script: []
  script:
  - &project_clean rm -rfv /cache/$CI_PROJECT_PATH_SLUG || true

cleanup_dockerregistry_caches: &cleanup_dockerregistry_caches
  <<: [ *cleanup_project ]
  script:
  - &proxycache_clean rm -rfv ${REGISTRIES_CACHE_DIR} || true

cleanup_dockercache: &cleanup_dockercache
  <<: [ *cleanup_project ]
  script:
  - &dockercache_clean rm -rfv ${DOCKER_CACHE} || true

cleanup_all: &cleanup_all
  <<: [ *cleanup_project ]
  script: [ *project_clean, *proxycache_clean, *dockercache_clean ]

.standalonebuilder: &standalonebuilder
  before_script: &standalonebuilder_before_script
  - *definefuncs
  - *waitforservices
  - *pullsubmodules
  - *install_bash
  - *settz
  - *gendotenv
  - *docker_auth
  - *setup_docker

.compose_build: &compose_build
  <<: [ *dind ]
  variables: &compose_build_vars
    <<: [ *dind_variables ]
    D_COMPOSE: "docker-compose"
    COMPOSE_HTTP_TIMEOUT:  "3600"
    MULTISTAGE_TARGET: ""
    BUILT_DOCKER_IMAGE: $CUR_DOCKER_IMAGE
    BUILT_LATEST_DOCKER_IMAGE: $LATEST_DOCKER_IMAGE
    BUILT_REF_DOCKER_IMAGE: $REF_DOCKER_IMAGE
    BUILT_DOCKER_IMAGE_VARNISH: $CUR_DOCKER_IMAGE_VARNISH
    BUILT_LATEST_DOCKER_IMAGE_VARNISH: $LATEST_DOCKER_IMAGE_VARNISH
    BUILT_REF_DOCKER_IMAGE_VARNISH: $REF_DOCKER_IMAGE_VARNISH
  script:
  - &build_dockercompose |-
    get_img() { jq -r .target.$service.tags[0]; }
    dc_() {
      ( : \
      && cimg=$(dcompose_bx_ --print "$@"|get_img) \
      && cachetag="$(echo ${BUILT_REF_DOCKER_IMAGE}-cache-${cachesuf})" \
      && vv dcompose_bx_ \
          $( if [ "x${MULTISTAGE_TARGET}" != "x" ];then echo '--set '"*.target=${MULTISTAGE_TARGET}";fi; ) \
          $( if [ "x${DOCKER_BASE_IMAGE-}" != "x" ];then echo '--set '"*.args.BASE=$(eval echo ${DOCKER_BASE_IMAGE})";fi; ) \
          --set "*.cache-to=type=local,dest=${docker_cache}.new,mode=max" \
          --set "*.cache-from=type=local,src=${docker_cache}" \
          --set "*.cache-to=type=registry,ref=${cachetag},mode=max" \
          --set "*.cache-from=type=registry,ref=${cachetag}" \
          --set "*.cache-from=type=registry,ref=${cimg}" "$@"; ); }
    dcompose_bx_build() { ( : \
      && service="$1";cachesuf="$2";COMPOSE_FILE="${3}";shift;shift;shift;docker_cache=${DOCKER_CACHE}/${cachesuf}/${service} \
      && dcexport="$(dcompose_bx_ --print $service|jq -r .target.$service)" && cimg="$(echo "$dcexport"|jq -r .tags[0])" \
      && log "Using buildkit to build $cimg :-: $dcexport" \
      && vv bx_dc ${service} $@; ); }
    vv dcompose_bx_build {{cookiecutter.app_type}} dev  ${COMPOSE_DEV_CONFIGS}
{%- if not cookiecutter.remove_varnish %}
{%- endif%}
    vv dcompose_bx_build {{cookiecutter.app_type}} prod ${COMPOSE_PROD_CONFIGS}
{%- if not cookiecutter.remove_varnish %}
    vv dcompose_bx_build varnish dev  ${COMPOSE_DEV_CONFIGS}
    vv dcompose_bx_build varnish prod ${COMPOSE_PROD_CONFIGS}
{%- endif%}
    # tag & record images for next step push
    dev_tags="";prod_tags="";
{%- if not cookiecutter.remove_varnish %}
    vdev_tags="";vprod_tags="";
{%- endif %}
    if ( echo ${CI_COMMIT_REF_NAME} | grep -E -q "$TAGGUABLE_IMAGE_BRANCH" );then
      dev_tags="$dev_tags   $(echo ${BUILT_REF_DOCKER_IMAGE}-dev)"
      prod_tags="$prod_tags $(echo ${BUILT_REF_DOCKER_IMAGE})"
{%- if not cookiecutter.remove_varnish %}
      vdev_tags="$vdev_tags   $(echo ${BUILT_REF_DOCKER_IMAGE_VARNISH}-dev)"
      vprod_tags="$vprod_tags $(echo ${BUILT_REF_DOCKER_IMAGE_VARNISH})"
{%- endif %}
    fi
    if [ "x${CI_COMMIT_REF_NAME}" = "x${MAIN_BRANCH}" ];then
      dev_tags="$dev_tags   $(echo ${BUILT_LATEST_DOCKER_IMAGE}-dev)"
      prod_tags="$prod_tags $(echo ${BUILT_LATEST_DOCKER_IMAGE})"
{%- if not cookiecutter.remove_varnish %}
      vdev_tags="$vdev_tags   $(echo ${BUILT_LATEST_DOCKER_IMAGE_VARNISH}-dev)"
      vprod_tags="$vprod_tags $(echo ${BUILT_LATEST_DOCKER_IMAGE_VARNISH})"
{%- endif %}
    fi
    if [ "x${dev_tags}" != "x" ];then  vv retry_cmd dcompose_bx_build {{cookiecutter.app_type}} dev  ${COMPOSE_DEV_CONFIGS}  $(bx_bake_tags $dev_tags);fi
    if [ "x${prod_tags}" != "x" ];then vv retry_cmd dcompose_bx_build {{cookiecutter.app_type}} prod ${COMPOSE_PROD_CONFIGS} $(bx_bake_tags $prod_tags);fi
{%- if not cookiecutter.remove_varnish %}
    if [ "x${vdev_tags}" != "x" ];then  vv retry_cmd dcompose_bx_build varnish dev  ${COMPOSE_DEV_CONFIGS}  $(bx_bake_tags $vdev_tags);fi
    if [ "x${vprod_tags}" != "x" ];then vv retry_cmd dcompose_bx_build varnish prod ${COMPOSE_PROD_CONFIGS} $(bx_bake_tags $vprod_tags);fi
{%- endif %}
    for s in {{cookiecutter.app_type}}{% if not cookiecutter.remove_varnish %} varnish{%endif%};do for c in dev prod;do swap_cache_folder ${DOCKER_CACHE}/$c/$s;done;done

{{docscomment and frontcomment}}.build_artifacts: &build_artifacts
{{docscomment and frontcomment}}  <<: [ *ci_runner ]
{{docscomment and frontcomment}}  before_script: []
{{docscomment and frontcomment}}  after_script: []
{{docscomment and frontcomment}}  services: []
{{docscomment and frontcomment}}  dependencies: []
{{docscomment and frontcomment}}  stage: build_artifacts
{{docscomment}}# BUILTIN DOCS support
{{docscomment}}build_docs: &build_docs
{{docscomment}}  <<: [ *build_artifacts ]
{{docscomment}}  image: "${LATEST_CI_DOCKER_IMAGE}-docsbuilder"
{{docscomment}}  artifacts: {name: docs, expire_in: "1 week", paths: ["{{'", "'.join(cookiecutter.docs_folders.split())}}"]}
{{docscomment}}  script:
{{docscomment}}  - export SOURCEDIR="$(pwd)/docs" BUILDDIR="$(pwd)/docs/_build"
{{docscomment}}  - NO_INSTALL="" /code/docs/entry.sh install_tools
{{docscomment}}  - /code/docs/entry.sh build_doc
{{frontcomment}}# BUILTIN Js APP support
{{frontcomment}}build_front: &build_front
{{frontcomment}}  <<: [ *build_artifacts ]
{{frontcomment}}  image: "${NODE_IMAGE}"
{{frontcomment}}  artifacts: {name: js, expire_in: "1 week", paths: ["{{'", "'.join(cookiecutter.statics_folders.split())}}"]}
{{frontcomment}}  cache: {key: jsdeps, paths: [node_modules]}
{{frontcomment}}  script:
{{frontcomment}}  - &front_setup |-
{{frontcomment}}      set -ex;
{{frontcomment}}      {% if cookiecutter.with_yarn%}yarn install{%else%}npm ci{%endif%}
{{frontcomment}}  - &front_build |-
{{frontcomment}}      set -ex;
{{frontcomment}}      $NPM_CONFIG;{% if cookiecutter.with_yarn%}yarn build{% else%}npm run build{%endif%}
{{frontcomment}}#  - &front_test |-
{{frontcomment}}#      set -ex;
{{frontcomment}}#      $NPM_CONFIG;{% if cookiecutter.with_yarn%}yarn test{% else%}npm run test{%endif%}
{{frontcomment}}force_build_front:
{{frontcomment}}  <<: [ *manual_job, *standalonebuilder, *build_front ]

build_ci_images: &build_ci_images
  <<: [ *compose_build, *ci_runner ]
  stage: build_ci
  variables: &build_ci_images_vars
    <<: [ *compose_build_vars ]
    MULTISTAGE_TARGET: ""
    BUILT_DOCKER_IMAGE: $CUR_CI_DOCKER_IMAGE
    BUILT_LATEST_DOCKER_IMAGE: $LATEST_CI_DOCKER_IMAGE
    BUILT_REF_DOCKER_IMAGE: $REF_CI_DOCKER_IMAGE
{%- if not cookiecutter.remove_varnish %}
    BUILT_DOCKER_IMAGE_VARNISH: $CUR_CI_DOCKER_IMAGE_VARNISH
    BUILT_LATEST_DOCKER_IMAGE_VARNISH: $LATEST_CI_DOCKER_IMAGE_VARNISH
    BUILT_REF_DOCKER_IMAGE_VARNISH: $REF_CI_DOCKER_IMAGE_VARNISH
{%- endif %}
  script: [ *build_dockercompose ]
  rules:
  - *skip_not_a_push_trigger
  - if: "$CI_COMMIT_REF_NAME == $MAIN_BRANCH"
    changes:
      paths:
      - "*Dockerfile*"
      - "{composer.json,app/composer.json,composer.lock,app/composer.lock}"
      - "docker-compose*.yml"
      - "{apt,yum,apk}.txt"
      - "{.env,docker.env}*"
{%-if cookiecutter.use_submodule_for_deploy_code%}
      - "${PROJECT_COMMON_DEPLOY_DIR}"
{%-endif%}
  - when: never

{{docscomment}}build_ci_docs_image: &build_ci_docs_image
{{docscomment}}  <<: [ *build_ci_images ]
{{docscomment}}  script:
{{docscomment}}  - &build_compose_docs |-
{{docscomment}}      set -e
{{docscomment}}      docker_cache=${DOCKER_CACHE}/docs
{{docscomment}}      dc_() {
{{docscomment}}        ( : \
{{docscomment}}        && rcache="type=registry,ref=$(echo ${REF_CI_DOCKER_IMAGE}-docsbuilder-cache)" \
{{docscomment}}        && cd docs \
{{docscomment}}        && COMPOSE_FILE="docker-compose.yml:docker-compose-build.yml" vv dcompose_bx_ \
{{docscomment}}        --set "*.cache-to=type=local,dest=${docker_cache}.new,mode=max" --set "*.cache-from=type=local,src=${docker_cache}" \
{{docscomment}}        --set "*.cache-to=$rcache,mode=max" --set "*.cache-from=$rcache" $@; ); }
{{docscomment}}      # tag & record images for next step push
{{docscomment}}      docs_tags=""
{{docscomment}}      if ( echo ${CI_COMMIT_REF_NAME} | grep -E -q "$TAGGUABLE_IMAGE_BRANCH" );then
{{docscomment}}        docs_tags="$docs_tags $(echo ${BUILT_REF_DOCKER_IMAGE})-docsbuilder"
{{docscomment}}      fi
{{docscomment}}      if [ "x${CI_COMMIT_REF_NAME}" = "x${MAIN_BRANCH}" ];then
{{docscomment}}        docs_tags="$docs_tags $(echo ${BUILT_LATEST_DOCKER_IMAGE})-docsbuilder"
{{docscomment}}      fi
{{docscomment}}      vv bx_dc docs
{{docscomment}}      if [ "x${docs_tags}" != "x" ];then vv retry_cmd bx_dc docs $(bx_bake_tags $docs_tags);fi
{{docscomment}}      swap_cache_folder ${docker_cache}
{{docscomment}}  rules:
{{docscomment}}  - *skip_not_a_push_trigger
{{docscomment}}  - if: "$CI_COMMIT_REF_NAME == $MAIN_BRANCH"
{{docscomment}}    changes:
{{docscomment}}      paths:
{{docscomment}}      - "{apt,yum,apk}.txt"
{{docscomment}}      - "docker-compose*.yml"
{{docscomment}}      - "*Dockerfile*doc*"
{{docscomment}}      - "{.env,docker.env}*"
{{docscomment}}      - "docs/{apt,yum,apk}.txt"
{{docscomment}}      - "docs/Dockerfile*"
{{docscomment}}      - "docs/{.env,docker.env}*"
{{docscomment}}      - "docs/requirements*"
{%-if cookiecutter.use_submodule_for_deploy_code%}
{{docscomment}}      - "${PROJECT_COMMON_DEPLOY_DIR}"
{%-endif%}
{{docscomment}}  - when: never

force_build_ci_images: &force_build_ci_images
  <<: [ *manual_releasable, *manual_job, *build_ci_images ]

{{docscomment}}force_build_ci_docs_image: &force_build_ci_docs_image
{{docscomment}}  <<: [ *manual_releasable, *manual_job, *build_ci_docs_image ]

.tests: &dottests
  <<: [ *ci_runner ]
  rules: [ *skip_mr_trigger, *skip_on_release_branches_tags_trigger, {when: on_success} ]
  stage: test
  image: "${BUILT_REF_DOCKER_IMAGE}-dev"
  variables: &test_vars
      <<: [ *service_vars, *variables ]
      # keep the over indent to facilitate sync with compose vars
      BUILT_REF_DOCKER_IMAGE: $LATEST_CI_DOCKER_IMAGE
{%- if not cookiecutter.remove_varnish %}
      BUILT_REF_DOCKER_IMAGE_VARNISH: $LATEST_CI_DOCKER_IMAGE_VARNISH
{%- endif %}
      CI: "true"
      TOX_CONFIG_FILE: "../tox.ini"
      # sync from compose:&env
      DB_MODE: "{{cookiecutter.db_mode}}"
      PHP_USER: "{{cookiecutter.php_user}}"
      PHP_GROUP: "{{cookiecutter.php_group}}"
      DRUPAL_ENV_NAME: "prod"
      APP_SECRET: "77fd8b950969a6909c46ab0b6fd5d062"
      IMAGE_MODE: phpfpm
      APP_TYPE: {{cookiecutter.app_type}}
      # docker variables that can be overriden via .env/docker.env
      # This need to be changed in production
      MAILCATCHER_USER: "mailcatcher"
      MAILCATCHER_PASSWORD: "mailcatcher"
      # parsed/replaced in CI via env-subst
      # Used in INSTALL ---------------
      PROFILE_NAME: "{{ cookiecutter.profile_name }}"
      SITE_NAME: "{{ cookiecutter.site_name }}"
      SITE_MAIL: "contact@{{ cookiecutter.mail_domain }}"
      ADMIN_MAIL: "sysadmin+{{ cookiecutter.lname }}@{{ cookiecutter.mail_domain }}"
      ADMIN_NAME: "admin"
      # ADMIN_PASS is set via ansible(and graved into .env) in production
      ADMIN_PASS: "admin"
      # or any other documented way before running install script
      SITE_DEFAULT_COUNTRY: "FR"
      DATE_DEFAULT_TIMEZONE: "Europe/Paris"
      UPDATE_STATUS_MODULE: "0"
      DRUPAL_NAME: "{{ cookiecutter.drupal_project_name }}"
      DRUPAL_URI: "http://{{cookiecutter.local_domain}}:{{cookiecutter.local_http_port}}"
      DRUSH_EXTRA_ARGS: "--uri=http://{{cookiecutter.local_domain}}:{{cookiecutter.local_http_port}}"
      # Key settings ------------------
      NGINX_SERVERNAME: "{{cookiecutter.name}}.local"
      NGINX_SERVER_ALIASES: "www.{{cookiecutter.name}}.local www2.{{cookiecutter.name}}.local"
      DRUPAL__ALLOWED_HOSTS: "{{cookiecutter.local_domain.replace(".","\\\\.")}}|www\\.{{cookiecutter.local_domain.replace(".","\\\\.")}}|www2\\.{{cookiecutter.local_domain.replace(".","\\\\.")}}"
      DRUPAL__HTTP_PROTECT_USER: ""
      DRUPAL__HTTP_PROTECT_PASSWORD: ""
      DATABASE_PREFIX: ""
{% if 'post' in cookiecutter.db_mode %}
      POSTGRES_STARTUP_TIMEOUT: "45s"
      POSTGRES_HOST: "db"
      POSTGRES_PORT: "5432"
      POSTGRES_DB: "db"
      POSTGRES_USER: "user"
      POSTGRES_PASSWORD: "password"
      PGPASSWD: "password"
      PGPASSWORD: "password"
      DATABASE_DRIVER: "pgsql"
      DATABASE_DB: "db"
      DATABASE_USER: "user"
      DATABASE_PASSWD: "password"
      DATABASE_HOST: "db"
      DATABASE_PORT: "5432"
      POSTGRES_MAX_CONNECTIONS: "200"
{% elif 'mysql' in cookiecutter.db_mode %}
      MYSQL_HOST: "db"
      MYSQL_PORT: "3306"
      MYSQL_DATABASE: "db"
      MYSQL_USER: "user"
      MYSQL_ROOT_PASSWORD: "password"
      MYSQL_PASSWORD: "password"
      DATABASE_DRIVER: "mysql"
      DATABASE_DB: "db"
      DATABASE_USER: "user"
      DATABASE_PASSWD: "password"
      DATABASE_HOST: "db"
      DATABASE_PORT: "3306"
{%- else %}
      DB_HOST: "db"
      DB_PORT: ""
      DB_NAME: "sites/default/files/.ht5.sqlite"
      DB_USER: "user"
      DB_PASSWORD: "password"
      DATABASE_DRIVER: "sqlite"
      DATABASE_DB: "sites/default/files/.ht5.sqlite"
      DATABASE_USER: "user"
      DATABASE_PASSWD: "password"
      DATABASE_HOST: "db"
      DATABASE_PORT: ""
{%- endif %}
      #
      COOKIE_DOMAIN: "{{cookiecutter.local_domain}}"
      ABSOLUTE_URL_SCHEME: "http"
      ABSOLUTE_URL_DOMAIN: "{{cookiecutter.local_domain}}"
      ABSOLUTE_URL_DOMAIN_ESCAPE: "{{cookiecutter.local_domain.replace('.', '\\\\.')}}"
      ABSOLUTE_URL_PORT: "{{cookiecutter.local_http_port}}"
      #
      PHP_MAX_WORKERS: "10"
      PHP_MAX_SPARE_WORKERS: "5"
      PHP_MIN_SPARE_WORKERS: "3"
      PHP_XDEBUG_ENABLED: "1"
      # VARNISH
      VARNISH__HTTP_PROTECT_USER: ""
      VARNISH__HTTP_PROTECT_PASSWORD: ""
      VARNISH_MEMORY_SIZE: "256MB"
      VARNISH_HIDE_X_CACHE_TAGS: ""
      VARNISH_BACKENDS: "nginx"
      VARNISH_NO_CACHE_COOKIE: "{{cookiecutter.no_cache_cookie}}"
      VARNISH_NO_CACHE_URL: "{{cookiecutter.no_cache_url}}"
      VARNISH_TTL_STATIC: "3h"
      VARNISH_TTL_STATIC_BROWSER: "86400"
      # Mail
      DRUPAL_SETTINGS__system_DOT_mail___interface_DOT_default: "SMTPMailSystem"
      DRUPAL_SETTINGS__smtp_DOT_settings___smtp_host: "mailcatcher"
      DRUPAL_SETTINGS__smtp_DOT_settings___smtp_port: "1025"
      DRUPAL_SETTINGS__smtp_DOT_settings___smtp_protocol: "standard"
      DRUPAL_SETTINGS__smtp_DOT_settings___smtp_autotls:  "raw:::true"
      DRUPAL_SETTINGS__smtp_DOT_settings___smtp_username: "mailcatcher"
      DRUPAL_SETTINGS__smtp_DOT_settings___smtp_password: "mailcatcher"
      PHP_MEMORY_LIMIT: "{{cookiecutter.php_memory_limit}}"
      TOPDIR:                  "$CI_PROJECT_DIR"
      BASE_DIR:                "$CI_PROJECT_DIR"
      ROOTPATH:                "$CI_PROJECT_DIR"
      TOPDIR_CANDIDATES:       "$CI_PROJECT_DIR"
      SRC_DIR:                 "$CI_PROJECT_DIR/app"
      ROOTPATH:                "$CI_PROJECT_DIR/app"
      PROJECT_DIR:             "$CI_PROJECT_DIR/app"
      COMPOSER_INSTALLED_FILE: "$CI_PROJECT_DIR/app/.composerinstalled"
      NO_MIGRATE: "1"
      NO_COLLECT_STATIC: "1"
      NO_STARTUP_LOGS: "1"
      NO_INSTALL: "1"
      NO_COMPOSER: "1"       
  #rules:
  ## do not run tests on deploy branches
  #- if: "$CI_COMMIT_REF_NAME =~ /^({{gitlabci_branches|join('|')}})$/ || $CI_PIPELINE_SOURCE =~ /schedule/"
  #  when: never
  services:
  - alias: db
    name: "{{cookiecutter["{0}_image".format(cookiecutter.db_mode)]}}"
{%- if cookiecutter.db_mode.startswith('post') %}
    entrypoint: ['sh', '-exc', 'docker-entrypoint.sh postgres -N $POSTGRES_MAX_CONNECTIONS']
{%- endif %}
    variables: &test_services_vars {<<: [ *test_vars ]}
{%- if cookiecutter.cache_system %}
  - alias: "{{cookiecutter.cache_system}}"
    name: "{{cookiecutter.cache_image}}"
    variables: {<<: [ *test_services_vars ]}
{%- endif %}
  - alias: mailcatcher
    name: "{{cookiecutter.mailhog_image}}"
    variables: {<<: [ *test_services_vars ]}
  - alias: nginx
    name: "{{cookiecutter.nginx_image}}"
    variables: {<<: [ *test_services_vars ], REFRESH_HOSTS_FROM_CI: "1", REFRESH_VHOST_FROM_CI: "1"}
{%- if not cookiecutter.remove_varnish%}
  - alias: varnish
    name: "$BUILT_REF_DOCKER_IMAGE_VARNISH"
    variables: {<<: [ *test_services_vars ], REFRESH_HOSTS_FROM_CI: "1", REFRESH_VCL_FROM_CI: "1"}
{%- endif%}
  before_script:
  - *definefuncs
  - *pullsubmodules
  - *install_bash
  - *settz
  - *gendotenv
  - *setup_docker_volumes
  - &waitfortestsservices |-
    set -e
    # configure /etc/hosts of both current job and it's associated services
    # code is on the services entrypoints to upstream the hosts block to their relative /etc/hosts
    if ( grep -q "\snginx" /etc/hosts );then echo "$(grep "\snginx" /etc/hosts|awk '{print $1}') $NGINX_SERVERNAME" >>/etc/hosts;fi
    grep -E "^[^#].*\s($NGINX_SERVERNAME|db|mysql|cache|redis|varnish|nginx|celery|memcach|cron|mailcatcher)" /etc/hosts >> "${COMMON_HOSTS_FILE}.tmp"
    export {{cookiecutter.app_type.upper()}}_IP="${FORCED_{{cookiecutter.app_type.upper()}}_IP:-$(ip -4 r get 8.8.8.8|grep src|awk '{print $7}')}"
    echo "${{cookiecutter.app_type.upper()}}_IP cron {{cookiecutter.app_type}}" >> "${COMMON_HOSTS_FILE}.tmp"
    mv "${COMMON_HOSTS_FILE}.tmp" "${COMMON_HOSTS_FILE}"
  - &regeninitdir |
    set -e && cd $CI_PROJECT_DIR && ( rm -rf init || true ) && mkdir init{% if cookiecutter.use_submodule_for_deploy_code%} && cp -rf $PROJECT_COMMON_DEPLOY_DIR/sys/* init/ {%endif%} && cp -rf sys/* init
  - &setup_tests |-
    set -e
    export SHELL_USER="{{cookiecutter.app_type}}"
    d=$CI_PROJECT_DIR;while ( echo $d | grep -q $CI_BUILDS_DIR );do od=$d;d=$(dirname $d);chmod u+rwx,g+x,o+x "$od" "$d";done
    chown -Rf $SHELL_USER $CI_PROJECT_DIR
    cd $SRC_DIR
  - &composerinstall set -e && cd $SRC_DIR && SHELL_USER=$(whoami) bin/composerinstall --no-scripts && touch "${COMPOSER_INSTALLED_FILE}"
  - &appmigrate cd $SRC_DIR && NO_STARTUP_LOGS= NO_COLLECT_STATIC= NO_INSTALL= DRUPAL_FORCE_INSTALL=1 ../init/init.sh bin/install.sh
{%- set testsc = (not cookiecutter.test_tests) and '#' or '' %}
{%- set testscov = (not cookiecutter.test_coverage) and '# ' or '' %}
{{testsc}}tests: &tests
{{testsc}}  <<: [ *dottests ]
{{testsc}}  script: &test_script
{{testsc}}  - &startup_{{cookiecutter.app_type}}_services |-
{{testsc}}    set -e
{{testsc}}{%-   set cfgs=['rsyslog', 'phpfpm'] %}
{{testsc}}{%- if not cookiecutter.remove_cron %}
{{testsc}}{%-     set _ = cfgs.extend(['cron']) %}
{{testsc}}{%- endif %}
{{testsc}}    ( export export SHELL_USER=root SUPERVISORD_CONFIGS='{{cfgs|join(' ')}}';vv /code/init/init.sh supervisord.sh)&
{{testsc}}  - &do_tests |-
{{testsc}}    set -e;
{{testsc}}    _curl() { curl -kvvvvvH "X-SSL: 1" -H "HOST: $NGINX_SERVERNAME" $@; }
{{testsc}}    drupal_ready() { _curl http://nginx 2>&1 |grep -iq  'x-Generator: drupal'; }
{{testsc}}    t=${DOCKER_SERVICES_TIMEOUT:-120} wait_ready drupal_ready
{{testsc}}  {{testscov}}coverage: '/^\s*Lines:\s*\d+.\d+\%/'

{%- set lintingc = (not cookiecutter.test_linting) and '#' or '' %}
{{lintingc}}linting:
{{lintingc}}  <<: [ *dottests ]
{{lintingc}}  script: &linting_script
{{lintingc}}  - &do_linting |-
{{lintingc}}    set -e && echo not implemented yet >&2
{{lintingc}}  allow_failure: true

build_and_release: &build_and_release
  stage: release
  dependencies: []
  rules: [ *skip_mr_trigger, *on_release_branches_main_tags_trigger, {when: never} ]
  <<: [ *compose_build, *ci_runner ]
  variables: &release_images_vars
    <<: [ *compose_build_vars ]
    DOCKER_BASE_IMAGE: $LATEST_CI_DOCKER_IMAGE

force_build_and_release: &force_build_and_release
  <<: [ *manual_job, *build_and_release]
  rules: [ *skip_mr_trigger, *mon_release_branches_main_tags_trigger, {when: never} ]

# the job will catch any failure on build stage and create a file upon success or failure
# the real goal is for teardown jobs in the next stage to run, in any cases
.flag_job: &flag_job
  <<: [ *ci_runner ]
  dependencies: []
  stage: end_flag
  before_script: []
  variables: {GIT_SUBMODULE_STRATEGY: none}

flag_success: &flag_success
  <<: [ *flag_job ]
  script: ["exit 0"]

flag_failure:
  <<: [ *flag_job ]
  when: on_failure
  script: ["exit 1"]

.teardown: &teardown
  <<: [ *ci_runner ]
  dependencies: []
  stage: post_release
  when: always
  before_script: []

teardown_workspace: &teardown_workspace
  <<: [ *teardown ]
  image: "busybox"
  variables: &teardown_workspace_vars {GIT_SUBMODULE_STRATEGY: none}
  before_script: []
  script:
  - &teardown_workspace_folder rm -rf ${WORKSPACE} || true

manual_teardown_workspace:
  <<: [ *manual_job, *teardown_workspace ]

.deploy: &deploy
  <<: [ *ci_runner ]
  dependencies: []
  allow_failure: false
  image: "${CORPUSOPS_IMAGE}"
  stage: post_release
  when: manual
  variables: &deploy_vars
    # you can use this on specific jobs to also backup databases & files prior to delivery
    # think in thise case to also setup what's to do in ansible inventory (files, medias or not)
    # DEPLOY_PLAYBOOK: ".ansible/playbooks/delivery.yml"
    DEPLOY_PLAYBOOK: .ansible/playbooks/app.yml
    A_ENV_NAME: "${CI_COMMIT_REF_NAME}"
    DEPLOYED_BRANCH: "${CI_COMMIT_REF_NAME}"
    DEPLOYED_TAG: "${CI_COMMIT_REF_NAME}"
  before_script:
  - &deploy_setup_vars |-
      set -e
      if [ "x${CI_COMMIT_REF_NAME}" = "x${MAIN_BRANCH}" ] && ( echo  "${CI_JOB_NAME}" | grep -q "deploy_dev$" );then export A_ENV_NAME="dev";fi
      export A_ENV_NAME=$(eval echo ${A_ENV_NAME})
      if [ "x${A_ENV_NAME}" = x ];then echo "\$A_ENV_NAME is not set, bailing out" >&2 ;exit 1;fi
      export DEPLOYED_BRANCH=$(eval echo ${DEPLOYED_BRANCH})
      export DEPLOYED_TAG=$(eval echo ${DEPLOYED_TAG})
  - *pullsubmodules
  - &deploy_setup set -e;vv(){ echo "$@">&2;"$@"; };
    vv .ansible/scripts/download_corpusops.sh;
    vv .ansible/scripts/setup_ansible.sh;
  - &deploy_key_setup set -e;vv(){ echo "$@">&2;"$@"; };
    vv .ansible/scripts/call_ansible.sh -vv .ansible/playbooks/deploy_key_setup.yml
  script:
  - &deploy_cmd |-
      # do not remove yaml inline (older gitlab parse problem)
      set -e
      .ansible/scripts/call_ansible.sh -vv -l $A_ENV_NAME "${DEPLOY_PLAYBOOK}" -e "{cops_{{cookiecutter.app_type}}_gitref: '$DEPLOYED_BRANCH', cops_{{cookiecutter.app_type}}_docker_tag: '$DEPLOYED_TAG', cops_{{cookiecutter.app_type}}_force_reinstall: $DJANGO_FORCE_INSTALL}"
{% for i in gitlabci_envs %}

.deploy_{{i}}_rules: &deploy_{{i}}_rules {only: {variables: ['{% if not cookiecutter.no_tags_pipelines%}$CI_COMMIT_TAG != null || {%endif%}$CI_COMMIT_REF_NAME == $MAIN_BRANCH || $CI_COMMIT_REF_NAME == "{{cookiecutter[i+'_branch']}}"']}}
.deploy_{{i}}: &deploy_{{i}}
  <<: [ *deploy_{{i}}_rules, *deploy ]
  variables: &deploy_{{i}}_vars
    <<: [ *deploy_vars ]
    A_ENV_NAME: {{i}}
{%- if i in ['prod'] %}
    DEPLOY_PLAYBOOK: .ansible/playbooks/delivery.yml
{%- endif %}
{%- if i in ['dev'] %}
  when: "on_success"
{%- endif %}
  environment:
    name: {{i}}
    url: https://{{cookiecutter[i+'_domain']}}
{% endfor %}

# reset jobs
{%- for i in gitlabci_envs %}
{%- set resetcomment = (i in ['staging', 'prod', 'preprod']) and '#  ' or '' %}

{{resetcomment}}deploy_{{i}}_reset: &deploy_{{i}}_reset
{{resetcomment}}  <<: [ *deploy_{{i}} ]
{{resetcomment}}  when: manual
{{resetcomment}}  variables:
{{resetcomment}}    <<: [ *deploy_{{i}}_vars ]
{{resetcomment}}    {{cookiecutter.app_type.upper()}}_FORCE_INSTALL: 1
{%- endfor %}

# Allow to immediatly trigger a deploy without waiting for the full pipeline to complete
# eg: redeploying after only issuing a deploy code or configuration change which does not impact artifacts.
{% for i in gitlabci_envs %}
manual_deploy_{{i}}: &manual_deploy_{{i}}
  <<: [ *deploy_{{i}}_rules, *manual_job, *deploy_{{i}} ]
  variables: { <<: *deploy_{{i}}_vars }
{%- endfor %}
{%- if cookiecutter.haproxy %}
# haproxy jobs
.haproxy: &haproxy
  variables: &deploy_haproxy_vars
    <<: [ *deploy_vars ]
    DEPLOY_PLAYBOOK: ".ansible/playbooks/haproxy.yml"
{%- for i in envs %}
{%- if cookiecutter[i+'_host'] %}

deploy_haproxy_{{i}}: &deploy_haproxy_{{i}}
  <<: [ *haproxy, *manual_job, *deploy_{{i}} ]
{%- endif -%}
{%- endfor-%}
{%- endif -%}
# manual promoting current branch related tag to selected deploy branches
.promote: &promote
  <<: [ *dind ]
  dependencies: []
  image: "${DOCKERDIND_IMAGE}"
  variables: &promote_vars
    <<: [ *dind_variables ]
    TO_PROMOTE: "${MAIN_BRANCH} {{aenvs|join (' ') }}"
    FROM_PROMOTE: latest
  when: manual
  image: "${CORPUSOPS_IMAGE}"
  stage: manual_jobs
  allow_failure: true
  script:
  - *definefuncs
  - &promote_script |-
    set -e
    t="$(eval echo "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${FROM_PROMOTE}")"
{%- if not cookiecutter.remove_varnish %}
    vt="$(eval echo "${DOCKER_REGISTRY}/${DOCKER_IMAGE_VARNISH}:${FROM_PROMOTE}")"
{%- endif %}
    # for flav in "" "-dev";do vv docker pull ${t}${flav};done
    for i in $(uniquify $(eval echo ${TO_PROMOTE}));do
       bx_adddockertag ${t} ${i}{%- if not cookiecutter.remove_varnish %} ${vt}{% endif %}
       if [ "x${i}" = "x${MAIN_BRANCH}" ];then bx_adddockertag ${t} latest{%- if not cookiecutter.remove_varnish %} ${vt}{% endif %};fi
    done
  after_script:
  - *remove_commonhosts_file

promote_all_envs: &main_promote_all_envs
  <<: [ *manual_releasable, *promote ]

promote_single_env: &promote_single_env
  <<: [ *manual_releasable, *promote ]
  variables: &promote_single_env_vars
    <<: [ *promote_vars ]
    TO_PROMOTE: "${CI_COMMIT_REF_NAME}"

.promote_and_deploy: &promote_and_deploy
  before_script:
  - *definefuncs
  - *pullsubmodules
  - *waitforservices
  - *gendotenv
  - *setupdotenv
  - *docker_auth
  - *deploy_setup_vars
  - *deploy_setup
  - *deploy_key_setup
  script:
  - *promote_script
  - *deploy_cmd
  variables: &promote_and_deploy_vars
    <<: [ *promote_single_env_vars ]
    FROM_PROMOTE: "$CI_COMMIT_REF_NAME"
    A_ENV_NAME: "${TO_PROMOTE}"
    DEPLOYED_BRANCH: "${TO_PROMOTE}"
    DEPLOYED_TAG: "${TO_PROMOTE}"
{% for i in gitlabci_envs %}

manual_promote_and_deploy_{{i}}: &promote_and_deploy_{{i}}
  <<: [ *promote_and_deploy, *promote, *manual_deploy_{{i}} ]
  variables: &promote_and_deploy_{{i}}_vars
    <<: [ *promote_and_deploy_vars, *deploy_{{i}}_vars ]
    TO_PROMOTE: "{{i}}"
promote_and_deploy_{{i}}: { <<: [ *promote_and_deploy_{{i}} ], stage: post_release }
{% endfor %}

# teleport environments from others
{{teleportcomment}}.teleport_env: &teleport_env
{{teleportcomment}}  image: ${CORPUSOPS_IMAGE}
{{teleportcomment}}  <<: [ *deploy ]
{{teleportcomment}}  when: manual
{{teleportcomment}}  dependencies: []
{{teleportcomment}}  allow_failure: true
{{teleportcomment}}  only: [{%if not cookiecutter.no_tags_pipelines%}tags, {%endif%}{{cookiecutter.main_branch}}, deploy]
{{teleportcomment}}  stage: manual_jobs
{{teleportcomment}}  variables: &teleport_env_vars
{{teleportcomment}}    <<: [ *deploy_vars ]
{{teleportcomment}}    orig: ""
{{teleportcomment}}    dest: ""
{{teleportcomment}}    A_ENV_NAME: teleport
{{teleportcomment}}    TELEPORT_MODE: default
{{teleportcomment}}    TELEPORT_MODES: makinastates|default|standard
{{teleportcomment}}  script:
{{teleportcomment}}  - &teleport_selfcheck |-
{{teleportcomment}}    set -e
{{teleportcomment}}    ret=
{{teleportcomment}}    if ! (echo "using orig: ${orig:?orig has to be defined and not null}" >&2 );then ret=1;fi
{{teleportcomment}}    if ! (echo "using dest: ${dest:?dest has to be defined and not null}" >&2 );then ret=1;fi
{{teleportcomment}}    if ! (echo "using TELEPORT_MODE: ${TELEPORT_MODE:?has to be defined and not null}" >&2 );then ret=1;fi
{{teleportcomment}}    if ! (echo ${TELEPORT_MODE}|grep -E -q "$TELEPORT_MODES");then echo invalid TELEPORT_MODE;ret=1;fi
{{teleportcomment}}    if [ "x${ret-}" != "x" ];then exit 1;fi
{{teleportcomment}}  - &teleport |-
{{teleportcomment}}    set -e;.ansible/scripts/call_ansible.sh -vv .ansible/playbooks/teleport.yml \
{{teleportcomment}}    -e "{teleport_destination: '$dest', teleport_origin: '$orig', teleport_mode: '${TELEPORT_MODE}'}"

{{teleportcomment}}# teleport_prod_from_oldprod:
{{teleportcomment}}#   <<: [ deploy_prod_rules, *teleport_env ]
{{teleportcomment}}#   variables:
{{teleportcomment}}#     <<: [ *teleport_env_vars ]
{{teleportcomment}}#     TELEPORT_MODE: makinastates
{{teleportcomment}}#     orig: oldprod
{{teleportcomment}}#     dest: prod

{%- for i in ['dev', 'qa', 'staging']%}
{%- if cookiecutter.get(i+'_host') %}
{{teleportcomment}}teleport_{{i}}_from_prod:
{{teleportcomment}}  <<: [ *manual_job, *deploy_{{i}}_rules, *teleport_env ]
{{teleportcomment}}  variables:
{{teleportcomment}}    <<: [ *teleport_env_vars ]
{{teleportcomment}}    orig: prod
{{teleportcomment}}    dest: {{i}}
{%- endif %}
{%- endfor %}

{%- set cypresscomment = (not cookiecutter.test_cypress) and '#  ' or '' %}
{{cypresscomment}}e2etests:
{{cypresscomment}}  image: "${CORPUSOPS_IMAGE}"
{{cypresscomment}}  <<: [ *deploy_dev_rules, *manual_job, *dind, *ci_runner ]
{{cypresscomment}}  stage: post_deploy
{{cypresscomment}}  variables: {CI: "true", COMPOSE_FILE: docker-compose.yml}
{{cypresscomment}}  script: ["./control.sh cypress_run https://{{cookiecutter.dev_domain}}"]
{{cypresscomment}}  artifacts: {paths: ["./e2e/cypress/screenshots", "./e2e/cypress/videos"], when: on_failure, expire_in: 4 hours}
